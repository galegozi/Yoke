#!/bin/bash

#SBATCH --job-name=diffusion_model_s<studyIDX>_e<epochIDX>
#SBATCH --account=<ACCOUNT>
#SBATCH --partition=<PARTITION>
#SBATCH --time=<TIME>
#SBATCH --nodes=<NODES>
#SBATCH --ntasks-per-node=<NTASKS_PER_NODE>
#SBATCH --gpus-per-node=<GPUS_PER_NODE>
#SBATCH --cpus-per-task=<CPUS_PER_TASK>
#SBATCH --output=study<studyIDX>_epoch<epochIDX>.out
#SBATCH --error=study<studyIDX>_epoch<epochIDX>.err
#SBATCH -vvv

# Set the master node's address and port
MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
MASTER_PORT=$(shuf -i 1024-65535 -n 1)  # Choose a random port
export MASTER_ADDR MASTER_PORT

# Check available GPUs
sinfo  -o "%P %.24G %N"
srun /usr/bin/echo $CUDA_AVAILABLE_DEVICES
nvidia-smi

# Specify NCCL communication
export NCCL_SOCKET_IFNAME=hsn0  # Check possible interfaces with `ip link show`

# Debugging distributed data parallel
# export NCCL_DEBUG=INFO
# export NCCL_DEBUG_SUBSYS=INIT

# Load correct conda environment
module load python/3.11-anaconda-2023.07
source activate
conda activate <YOKE_TORCH_ENV>

# Set number of threads per GPU
export OMP_NUM_THREADS=10

# Get start time
export date00=`date`

# Start the Code
# Explicitly set TCP environment for the following...
srun python -u <train_script> @<INPUTFILE>

# Get end time and print to stdout
export date01=`date`

echo "===================TIME STARTED==================="
echo $date00
echo "===================TIME FINISHED==================="
echo $date01
